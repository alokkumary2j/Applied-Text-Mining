{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import operator\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isPunct(word):\n",
    "    return len(word) == 1 and word in string.punctuation\n",
    "\n",
    "def isNumeric(word):\n",
    "    try:\n",
    "        float(word) if '.' in word else int(word)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RakeKeywordExtractor:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stopwords = set(nltk.corpus.stopwords.words())\n",
    "        self.top_fraction = 1 # consider top third candidate keywords by score\n",
    "\n",
    "    def _generate_candidate_keywords(self, sentences):\n",
    "        phrase_list = []\n",
    "        for sentence in sentences:\n",
    "            #Replaces all StopWords by \"|\" and lowercases all words\n",
    "            words = map(lambda x: \"|\" if x in self.stopwords else x,nltk.word_tokenize(sentence.lower()))\n",
    "            ##words => NONSTOPWORD | NONSTOPWORD NONSTOPWORD NONSTOPWORD | | NONSTOPWORD | NONSTOPWORD NONSTOPWORD |\n",
    "            phrase = []\n",
    "            for word in words:\n",
    "                if word == \"|\" or isPunct(word):\n",
    "                    if len(phrase) > 0:\n",
    "                        phrase_list.append(phrase)#Got At least 1 NonStopWord\n",
    "                    phrase = []#Prepare for Next Continous NonStopWords\n",
    "                else:\n",
    "                    phrase.append(word)#NonStopWord\n",
    "        return phrase_list\n",
    "\n",
    "    def _calculate_word_scores(self, phrase_list):\n",
    "        word_freq = nltk.FreqDist()\n",
    "        word_degree = nltk.FreqDist()\n",
    "        for phrase in phrase_list:\n",
    "            #degree = len(list(filter(lambda x: not isNumeric(x), phrase))) - 1#Number of Words in the Phrase-1\n",
    "            for word in phrase:\n",
    "                word_freq[word] += 1\n",
    "                word_degree[word]+=1\n",
    "            for word in word_freq.keys():\n",
    "                word_degree[word] = word_degree[word] + word_freq[word] # itself\n",
    "        # word score = deg(w) / freq(w)\n",
    "        word_scores = {}\n",
    "        for word in word_freq.keys():\n",
    "            word_scores[word] = word_degree[word] / word_freq[word]\n",
    "        return word_scores\n",
    "\n",
    "    def _calculate_phrase_scores(self, phrase_list, word_scores):\n",
    "        phrase_scores = {}\n",
    "        for phrase in phrase_list:\n",
    "            phrase_score = 0\n",
    "            for word in phrase:\n",
    "                phrase_score += word_scores[word]\n",
    "                phrase_scores[\" \".join(phrase)] = phrase_score\n",
    "        return phrase_scores\n",
    "    \n",
    "    def extract(self, text, incl_scores=False):\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        phrase_list = self._generate_candidate_keywords(sentences)\n",
    "        word_scores = self._calculate_word_scores(phrase_list)\n",
    "        phrase_scores = self._calculate_phrase_scores(\n",
    "        phrase_list, word_scores)\n",
    "        sorted_phrase_scores = sorted(phrase_scores.items(),\n",
    "        key=operator.itemgetter(1), reverse=True)\n",
    "        n_phrases = len(sorted_phrase_scores)\n",
    "        if incl_scores:\n",
    "            return sorted_phrase_scores[0:int(n_phrases/self.top_fraction)]\n",
    "        else:\n",
    "            return map(lambda x: x[0],sorted_phrase_scores[0:int(n_phrases/self.top_fraction)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def explainCandidateGeneration():\n",
    "    rake=RakeKeywordExtractor()\n",
    "    testSent=\"This is a test sentence to explain the candidate generation strategy for automatic key phrase extraction.\"\n",
    "    cands=rake._generate_candidate_keywords([testSent])\n",
    "    print(\"Sentence ~~> \")\n",
    "    print(testSent)\n",
    "    print()\n",
    "    print(\"Generated Cadidates ~~> \")\n",
    "    print(cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ~~> \n",
      "This is a test sentence to explain the candidate generation strategy for automatic key phrase extraction.\n",
      "\n",
      "Generated Cadidates ~~> \n",
      "[['test', 'sentence'], ['explain'], ['candidate', 'generation', 'strategy'], ['automatic', 'key', 'phrase', 'extraction']]\n"
     ]
    }
   ],
   "source": [
    "explainCandidateGeneration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('linear diophantine equations', 84.0), ('linear constraints', 63.0), ('natural numbers', 62.0), ('strict inequations', 51.5), ('nonstrict inequations', 50.5), ('minimal generating sets', 49.666666666666664), ('upper bounds', 46.0), ('minimal supporting set', 45.33333333333333), ('minimal set', 36.333333333333336), ('compatibility', 32.0), ('system', 28.0), ('corresponding algorithms', 26.0), ('components', 22.0), ('considered types', 21.833333333333332), ('criteria', 21.0), ('set', 20.666666666666668), ('construction', 18.0), ('algorithms', 15.0), ('solutions', 14.666666666666666), ('considered', 14.5), ('systems', 13.75), ('given', 13.0), ('constructing', 10.0), ('mixed types', 9.333333333333332), ('types', 7.333333333333333), ('used', 7.0), ('solving', 6.0)]\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    rake = RakeKeywordExtractor()\n",
    "    keywords = rake.extract(\"\"\"\n",
    "    Compatibility of systems of linear constraints over the set of natural \n",
    "    numbers. Criteria of compatibility of a system of linear Diophantine \n",
    "    equations, strict inequations, and nonstrict inequations are considered. \n",
    "    Upper bounds for components of a minimal set of solutions and algorithms \n",
    "    of construction of minimal generating sets of solutions for all types of \n",
    "    systems are given. These criteria and the corresponding algorithms for \n",
    "    constructing a minimal supporting set of solutions can be used in solving \n",
    "    all the considered types of systems and systems of mixed types.\n",
    "    \"\"\", incl_scores=True)\n",
    "    print(keywords)\n",
    "  \n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
